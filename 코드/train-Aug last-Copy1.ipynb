{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "143d7c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/upload/\n",
      "파일 개수는: 4493\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Retrain the YOLO model for your own dataset.\n",
    "\"\"\"\n",
    "#이미지 증강\n",
    "import os\n",
    "#from pathlib import Path\n",
    "\n",
    "HOME_DIR = 'C:/upload/'\n",
    "\n",
    "ANNO_DIR = 'C:/upload/'\n",
    "#xml 파일들\n",
    "\n",
    "\n",
    "print(ANNO_DIR)\n",
    "\n",
    "\n",
    "files = os.listdir(ANNO_DIR)\n",
    "\n",
    "print('파일 개수는:',len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2662943b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.python.ops import control_flow_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47d3090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#LOCAL_DIR = os.path.abspath(\"c:/test/SED\")\n",
    "#sys.path.append(LOCAL_DIR)\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8a6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_classes, get_anchors\n",
    "from train import create_model, data_generator, data_generator_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf41c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 개수 4\n",
      "-------------------CLASS NAMES-------------------\n",
      "['helmet', 'non_helmet', 'vest', 'non_vest']\n",
      "-------------------CLASS NAMES-------------------\n"
     ]
    }
   ],
   "source": [
    "#학습을 위한 기반 환경 설정. \n",
    "annotation_path = 'c:/upload/annotation.csv'\n",
    "log_dir = 'c:/test/logs/000/'  #epoch 당 weight 저장 장소로 사용할 될 폴더.\n",
    "classes_path = 'c:/test/model_data/helmetvest_classes.txt'  #내가 클래스 2개로 설정.\n",
    "anchors_path = 'c:/test/model_data/yolo_anchors.txt'\n",
    "model_weights_path = 'c:/test/model_data/yolo.h5'\n",
    "\n",
    "\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names) #클래스 개수\n",
    "print(\"클래스 개수\", num_classes)\n",
    "anchors = get_anchors(anchors_path)\n",
    "# anchors\n",
    "# 검출객체 너비, 높이의 초기값으로 주어진 값들로 이 초기값들이 리사이즈되어 실제 검출 객체 크기가 된다.\n",
    "\n",
    "\n",
    "print(\"-------------------CLASS NAMES-------------------\")\n",
    "print(class_names)\n",
    "print(\"-------------------CLASS NAMES-------------------\")\n",
    "\n",
    "\n",
    "input_shape = (416,416)\n",
    "#이미지 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf1fdf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Create YOLOv3 model with 9 anchors and 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((1, 1, 1024, 27) vs (255, 1024, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_59 due to mismatch in shape ((27,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((1, 1, 512, 27) vs (255, 512, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_67 due to mismatch in shape ((27,) vs (255,)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((1, 1, 256, 27) vs (255, 256, 1, 1)).\n",
      "  weight_values[i].shape))\n",
      "C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\engine\\saving.py:1319: UserWarning: Skipping loading of weights for layer conv2d_75 due to mismatch in shape ((27,) vs (255,)).\n",
      "  weight_values[i].shape))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights c:/test/model_data/yolo.h5.\n",
      "Freeze the first 249 layers of total 252 layers.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py:4138: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "tiny = len(anchors)==6 # 기본값 세팅\n",
    "# create_tiny_model(), create_model() 함수의 인자 설정을 원본 train.py에서 수정. \n",
    "if tiny:\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path=model_weights_path)\n",
    "else:\n",
    "    # create_model 은 해당 패키지의 tarin.py 내부에 있는 클래스를 사용. 이 함수는 keras 모듈이 많이 사용한다.\n",
    "    model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path=model_weights_path) \n",
    "\n",
    "# epoch 마다 call back 하여 모델 파일 저장.\n",
    "# 이것 또한 Keras에서 많이 사용하는 checkpoint 저장 방식인듯 하다.\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "# ModelCheckpoint는 모델이 학습하면서 정의한 조건을 만족했을 때 Model의 weight 값을 중간 저장\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "    # period - 모델 저장 주기를 결정하는 것으로 값이 1인 경우 매 학습시마다 저장하게 됩니다. \n",
    "lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "# ModelCheckpoint - 모델을 저장할 때 사용되는 콜백함수.\n",
    "# ReduceLROnPlateau - 지정된 기간동안 평가지표에서 성능 향상이 일어나지 않으면 학습률을 조정하는 콜백\n",
    "# save_best-only - True 인 경우, monitor 되고 있는 값을 기준으로 가장 좋은 값으로 모델이 저장됨.\n",
    "# save_weights_only - True인 경우, 모델의 weights만 저장됩니다\n",
    "\n",
    "# monitor - 모델을 저장할 때, 기준이 되는 값을 지정함.\n",
    "# validation set의 loss가 가장 작을 때 저장하고 싶으면 'val_loss'를 입력\n",
    "# train set의 loss가 가장 작을 때 모델을 저장하고 싶으면 'loss'를 입력\n",
    "\n",
    "# verbose - 1\n",
    "# 1일 경우 Epoch의 상황과 loss 값이 보여짐. Epoch가 진행되는 막대도 보여줌.\n",
    "\n",
    "\n",
    "# patience\n",
    "#  - mode 파라미터에서 지정한 값으로 상태에 도달했을 때 바로 종료시키지 않고 몇 번 더 학습시킬 것인지 결정합니다.\n",
    "#  monitor='val_loss' 이고 mode='min', patience=4이면 검증데이터셋의 비용함수가 최저점이 되어도\n",
    "#  4번은 더 학습시켜라 라는 뜻\n",
    "\n",
    "# factor - 학습률이 감소되는 요소\n",
    "\n",
    "'''\n",
    "Early Stopping.\n",
    "  너무 많은 Epoch 은 overfitting 을 일으킨다.\n",
    "  하지만 너무 적은 Epoch 은 underfitting 을 일으킨다.\n",
    "  그래서 Epoch를 많이 돌리고 특정 시점에서 멈추도록 하여 성능이 더 이상 증가하지 않으면\n",
    "  학습을 중지시키도록 함.\n",
    "  \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da543441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n",
      "449\n"
     ]
    }
   ],
   "source": [
    "val_split = 0.2  # train data : val_data 를 8 : 2 로 설정함.\n",
    "\n",
    "with open(annotation_path) as f:\n",
    "    # with_open 하면 annotation 파일이 txt이든 csv이든 상관없음.\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 랜덤 시드 생성 및 lines 셔플하기\n",
    "np.random.seed(10101)\n",
    "#np.random.seed() : 난수 생성.\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "\n",
    "# 데이터셋 나누기\n",
    "valnum = int(len(lines)*val_split)\n",
    "trainnum = len(lines) - valnum\n",
    "print(trainnum)\n",
    "print(valnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fb04810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1797 samples, val on 449 samples, with batch size 8.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:200: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:203: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/50\n",
      "224/224 [==============================] - 846s 4s/step - loss: 472.8948 - val_loss: 82.6133\n",
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\test\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/50\n",
      "224/224 [==============================] - 818s 4s/step - loss: 56.2895 - val_loss: 53.0884\n",
      "Epoch 3/50\n",
      "224/224 [==============================] - 817s 4s/step - loss: 42.9995 - val_loss: 43.8043\n",
      "Epoch 4/50\n",
      "224/224 [==============================] - 833s 4s/step - loss: 38.5441 - val_loss: 35.2510\n",
      "Epoch 5/50\n",
      "224/224 [==============================] - 969s 4s/step - loss: 35.9535 - val_loss: 32.9630\n",
      "Epoch 6/50\n",
      "224/224 [==============================] - 1042s 5s/step - loss: 34.0208 - val_loss: 37.6276\n",
      "Epoch 7/50\n",
      "224/224 [==============================] - 1047s 5s/step - loss: 33.1691 - val_loss: 40.5894\n",
      "Epoch 8/50\n",
      "224/224 [==============================] - 1044s 5s/step - loss: 32.2862 - val_loss: 37.3922\n",
      "Epoch 9/50\n",
      "224/224 [==============================] - 1014s 5s/step - loss: 31.6249 - val_loss: 42.3116\n",
      "Epoch 10/50\n",
      "224/224 [==============================] - 972s 4s/step - loss: 30.8872 - val_loss: 28.3704\n",
      "Epoch 11/50\n",
      "224/224 [==============================] - 831s 4s/step - loss: 30.4757 - val_loss: 43.7646\n",
      "Epoch 12/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 30.1066 - val_loss: 29.0173\n",
      "Epoch 13/50\n",
      "224/224 [==============================] - 830s 4s/step - loss: 29.9460 - val_loss: 26.4267\n",
      "Epoch 14/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 29.7108 - val_loss: 28.8951\n",
      "Epoch 15/50\n",
      "224/224 [==============================] - 829s 4s/step - loss: 29.0337 - val_loss: 24.6883\n",
      "Epoch 16/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 28.9486 - val_loss: 25.1931\n",
      "Epoch 17/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 28.6180 - val_loss: 32.9670\n",
      "Epoch 18/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 28.7018 - val_loss: 26.2757\n",
      "Epoch 19/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 28.2935 - val_loss: 26.6767\n",
      "Epoch 20/50\n",
      "224/224 [==============================] - 845s 4s/step - loss: 28.4196 - val_loss: 24.2818\n",
      "Epoch 21/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 27.9860 - val_loss: 25.9964\n",
      "Epoch 22/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 27.8761 - val_loss: 32.5193\n",
      "Epoch 23/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 27.9744 - val_loss: 29.7219\n",
      "Epoch 24/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 27.5726 - val_loss: 28.4941\n",
      "Epoch 25/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 27.5497 - val_loss: 40.8258\n",
      "Epoch 26/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 27.3769 - val_loss: 35.7419\n",
      "Epoch 27/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 27.2194 - val_loss: 25.2210\n",
      "Epoch 28/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 27.0309 - val_loss: 28.3785\n",
      "Epoch 29/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 27.0201 - val_loss: 32.2770\n",
      "Epoch 30/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 26.8965 - val_loss: 38.5264\n",
      "Epoch 31/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.7338 - val_loss: 29.4541\n",
      "Epoch 32/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 26.6907 - val_loss: 31.6392\n",
      "Epoch 33/50\n",
      "224/224 [==============================] - 827s 4s/step - loss: 26.7997 - val_loss: 22.5890\n",
      "Epoch 34/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.6460 - val_loss: 33.4876\n",
      "Epoch 35/50\n",
      "224/224 [==============================] - 825s 4s/step - loss: 26.2397 - val_loss: 23.2210\n",
      "Epoch 36/50\n",
      "224/224 [==============================] - 825s 4s/step - loss: 26.3775 - val_loss: 22.2355\n",
      "Epoch 37/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.5142 - val_loss: 29.7124\n",
      "Epoch 38/50\n",
      "224/224 [==============================] - 825s 4s/step - loss: 26.2306 - val_loss: 27.0451\n",
      "Epoch 39/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.0655 - val_loss: 28.4143\n",
      "Epoch 40/50\n",
      "224/224 [==============================] - 828s 4s/step - loss: 26.1247 - val_loss: 31.5375\n",
      "Epoch 41/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.1659 - val_loss: 27.2553\n",
      "Epoch 42/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.0549 - val_loss: 22.6690\n",
      "Epoch 43/50\n",
      "224/224 [==============================] - 826s 4s/step - loss: 26.2753 - val_loss: 23.6871\n",
      "Epoch 44/50\n",
      "224/224 [==============================] - 839s 4s/step - loss: 25.7146 - val_loss: 24.9807\n",
      "Epoch 45/50\n",
      "224/224 [==============================] - 836s 4s/step - loss: 25.8428 - val_loss: 25.8579\n",
      "Epoch 46/50\n",
      "224/224 [==============================] - 837s 4s/step - loss: 25.9948 - val_loss: 31.2643\n",
      "Epoch 47/50\n",
      "224/224 [==============================] - 835s 4s/step - loss: 25.6969 - val_loss: 24.4778\n",
      "Epoch 48/50\n",
      "224/224 [==============================] - 830s 4s/step - loss: 25.7600 - val_loss: 22.1435\n",
      "Epoch 49/50\n",
      "224/224 [==============================] - 833s 4s/step - loss: 25.9915 - val_loss: 33.6585\n",
      "Epoch 50/50\n",
      "224/224 [==============================] - 843s 4s/step - loss: 25.6375 - val_loss: 25.1588\n",
      "Unfreeze all of the layers.\n",
      "Train on 1797 samples, val on 449 samples, with batch size 8.\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 2454s 11s/step - loss: 23.9460 - val_loss: 20.4072\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 2509s 11s/step - loss: 21.6433 - val_loss: 25.5349\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 2458s 11s/step - loss: 20.6962 - val_loss: 20.9842\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 2434s 11s/step - loss: 20.2545 - val_loss: 18.7388\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 2395s 11s/step - loss: 19.6489 - val_loss: 23.4554\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 2384s 11s/step - loss: 19.3519 - val_loss: 22.7982\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 2391s 11s/step - loss: 19.0454 - val_loss: 18.1016\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 2395s 11s/step - loss: 19.0693 - val_loss: 20.0937\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 2392s 11s/step - loss: 18.6154 - val_loss: 16.0871\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 2386s 11s/step - loss: 18.4948 - val_loss: 19.2191\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 2386s 11s/step - loss: 18.4060 - val_loss: 14.0415\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 2435s 11s/step - loss: 18.0269 - val_loss: 18.1358\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 2468s 11s/step - loss: 18.1081 - val_loss: 15.0403\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 2543s 11s/step - loss: 17.6687 - val_loss: 19.3258\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 2550s 11s/step - loss: 17.1020 - val_loss: 19.6552\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 2550s 11s/step - loss: 16.8406 - val_loss: 16.4347\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 2645s 12s/step - loss: 16.6379 - val_loss: 14.9042\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/224 [==============================] - 2643s 12s/step - loss: 16.6338 - val_loss: 20.6594\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 2492s 11s/step - loss: 16.5910 - val_loss: 14.8854\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 2515s 11s/step - loss: 16.6456 - val_loss: 21.2572\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 2510s 11s/step - loss: 16.5406 - val_loss: 18.3884\n",
      "Epoch 00071: early stopping\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "stable loss 얻기 위해서 frozen layers를 먼저 train 함.\n",
    "weight 값은 처음에 random 값으로 초기화 되어 있는데 이 경우 최적화된 weight값을 찾으려면\n",
    "많은 학습 횟수가 필요할 수 있다. 그런데 pretrained 모델에서 초기부터 이미 최적화된 \n",
    "weight 값을 기반해서 학습을 하면 좋은 성능이 나타날 수 있다.\n",
    "일단 처음에 weight값을 학습하지 않고 별도의 classification layer (fully connected layer)\n",
    "부터 먼저 일정 수준 학습을 시킨 다음에 feature extractor를 포함한 전체를 학습\n",
    "'''\n",
    "\n",
    "'''\n",
    "fully connected layer : 이미지를 정의된 라벨로 분류하는 데 사용\n",
    "한층의 모든 뉴런이 다음층이 모든 뉴런과 연결된 상태로\n",
    "2차원의 배열 형태 이미지를 1차원의 평탄화 작업을 통해 이미지를 분류하는데 사용되는 계층\n",
    "\n",
    "feature extractor(특징 추출) : 컴퓨터가 스스로 학습을 할 때 컴퓨터가 입력받은 데이터를 분석해서 일정한\n",
    "패턴이나 규칙을 찾아내려면 컴퓨터가 인지할 수 있는 데이터로 변환해주어야 함.\n",
    "이 때 데이터 별로 어떤 특징을 가지고 있는지를 찾아내고, 그것을 토대로 데이터를 벡터로 변환하는 \n",
    "작업을 말한다.\n",
    "\n",
    "먼저 50epoch 로 classification layer를 학습.\n",
    "classification layer를 학습 한 뒤에는 이제 feature map과 classification layer를 모두 포함한 전체 layer를 다시 50회 학습합니다. \n",
    "그래서 model.layers[i].trainable = True로 변경합니다.\n",
    "'''\n",
    "\n",
    "# feature map - 이미지가 가지는 edge, texture, 형태등을 표현\n",
    "# classification layer - \n",
    "if True:\n",
    "    # Model의 optimizer(최적화)와 loss, metrics를 선택\n",
    "    #adam이 빠르고 성능 좋고 무난.\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "        \n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "    batch_size = 8\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(trainnum, valnum, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:trainnum], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, trainnum//batch_size),\n",
    "            # 훈련 샘플 수 / 배치 사이즈\n",
    "            validation_data=data_generator_wrapper(lines[trainnum:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, valnum//batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "\n",
    "# 결과가 좋지 않다면 train 이어서 진행. (두 학습이 모델을 이어서 함.)\n",
    "\n",
    "if True:\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "    print('Unfreeze all of the layers.')\n",
    "    # 모든 레이어 Unfreeze 한다. fine tuning 하기 위해서\n",
    "    # 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적(나의 이미지 데이터에 맞게)변형하고 이미 학습된 모델 \n",
    "    # Weights로 부터 학습을 업데이트하는 방법\n",
    "\n",
    "    batch_size = 8\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(trainnum, valnum, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:trainnum], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, trainnum//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[trainnum:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, valnum//batch_size),\n",
    "        epochs=100,\n",
    "        initial_epoch=50,\n",
    "        callbacks=[logging, checkpoint, lr, early_stopping])\n",
    "    model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "# data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes)\n",
    "# 이 파라미터들을  data_generator()함\n",
    "# -> 이미지 데이터와 박스 데이터 리시트를 만들고 어노테이션 라인들 섞어서 \n",
    "\n",
    "# save_best_only - True, False\n",
    "# True 인 경우, monitor 되고 있는 값을 기준으로 가장 좋은 값으로 모델이 저장됨.\n",
    "# 모델의 정확도가 최고값을 갱신했을 때만 저장하도록 하는 옵션\n",
    "\n",
    "\n",
    "# save_weights_only - True, False\n",
    "# Weights만 저장할 지 여부\n",
    "# True인 경우, 모델의 weights만 저장됨.\n",
    "# False인 경우, 모델 레이어 및 weights 모두 저장됨.\n",
    "# layer 구성, 노드 갯수, 노드 정보, activation 정보 등의 값을 같이 저장한다\n",
    "\n",
    "# fit_generator() - fit()은 전체 dataset을 한 번에 fit method로 통과시켜서 전체 dataset을 메모리에 로드할 수 있는, \n",
    "# 작은 크기의 dataset으로 학습을 시킬 때 사용.\n",
    "# fit_generator()는 x,y 를 직접적으로 통과시키지 않고, generator를 통해 데이터를 불러오고 Multiprocessing을 진행할 때\n",
    "# 데이터 중복을 막기 위해서 사용. 큰 크기의 dataset으로 학습을 시킬 때 사용.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c039dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0f601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
